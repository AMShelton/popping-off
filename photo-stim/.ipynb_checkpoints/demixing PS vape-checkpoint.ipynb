{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import sys\n",
    "sys.path.append('/home/tplas/repos/Vape/')\n",
    "sys.path.append('/home/tplas/repos/Vape/utils')\n",
    "sys.path.append('/home/tplas/repos/Vape/jupyter/')\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils_funcs as utils\n",
    "import run_functions as rf\n",
    "from subsets_analysis import Subsets\n",
    "import pickle\n",
    "from dPCA import dPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'setup_notebook.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run setup_notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading mouse RL048, run 23\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "pkl_path = '/mnt/qnap_jrowland/run_pkls'\n",
    "\n",
    "\n",
    "# dictionary of mice and run numbers to analyse\n",
    "run_dict = {\n",
    "            'J048' : [27, 29, 30, 32], \n",
    "            'RL048': [23, 24, 25, 28, 29]\n",
    "           }\n",
    "\n",
    "# local path to behaviour pickle files\n",
    "# this takes a while to load so maybe should do some further caching in the future\n",
    "# pkl_path = '/home/jamesrowland/Documents/Code/Vape/run_pkls/'\n",
    "\n",
    "runs = []\n",
    "mouse = 'RL048'\n",
    "run_number = 23\n",
    "# for run_number in run_dict[mouse]:\n",
    "print(f'Now loading mouse {mouse}, run {run_number}')\n",
    "run_path = os.path.join(pkl_path, mouse, 'run{}.pkl'.format(run_number))\n",
    "with open(run_path, 'rb') as f:\n",
    "    r = pickle.load(f)\n",
    "    runs.append(r)\n",
    "\n",
    "# runs = []\n",
    "# for mouse in run_dict:\n",
    "#     for run_number in run_dict[mouse]:\n",
    "#         print(f'Now loading mouse {mouse}, run {run_number}')\n",
    "#         run_path = os.path.join(pkl_path, mouse, 'run{}.pkl'.format(run_number))\n",
    "#         with open(run_path, 'rb') as f:\n",
    "#             r = pickle.load(f)\n",
    "#             runs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[0].__dict__['stat'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect data\n",
    "\n",
    "# runs[0].__dict__.keys()\n",
    "\n",
    "# processed (neuropil subtracted and Df/f) fluoresence matrix from first run\n",
    "flu = runs[0].flu\n",
    "print('This run has {} cells and {} frames'.format(flu.shape[0], flu.shape[1]))\n",
    "\n",
    "# plot the first 10 cells in the first run\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(10):\n",
    "    plt.plot(flu[i,:] + i*3)\n",
    "plt.title('Example data of first 10 cells')\n",
    "# run objects have info from the suite2p stat (1xdictionary per cell\n",
    "# used to e.g. find the plane each cell is in\n",
    "plane0_idx = [idx for idx, s in enumerate(runs[0].stat) if s['iplane']==0]\n",
    "\n",
    "# ## Find plane_0 neurons:\n",
    "# # run objects have info from the suite2p stat (1xdictionary per cell\n",
    "# # used to e.g. find the plane each cell is in\n",
    "# plane0_idx = [idx for idx, s in enumerate(runs[0].stat) if s['iplane']==0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = (10, 10)\n",
    "# plt.plot(galvo_ms / 1e6, trial_start[:] /1e6, '.-')\n",
    "# print(run_number, mouse)\n",
    "# # np.isnan(galvo_ms)\n",
    "# runs[0].aligner.A_to_B\n",
    "# -1\n",
    "# trial_start.shape\n",
    "# tstart_galvo.shape\n",
    "# mouse, run_number\n",
    "\n",
    "# runs[0].frames_ms.shape\n",
    "# runs[0].flu.shape\n",
    "plt.imshow(np.isnan(runs[0].frames_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Align with  behaviour:\n",
    "#### two timestamps for the onset of photostimulation ####\n",
    "\n",
    "# when is voltage sent to the x photostimulation galvo\n",
    "tstart_galvo = utils.threshold_detect(runs[0].x_galvo_uncaging, 0)\n",
    "\n",
    "# when did the behaviour microcontroller trigger a trial start\n",
    "trial_start = runs[0].trial_start\n",
    "# if (run_number == 29 and mouse == 'J048') or (run_number == 29 and mouse == 'RL048'):\n",
    "#     slope = (trial_start[-2] - trial_start[0]) / (tstart_galvo[-1] - tstart_galvo[0])\n",
    "#     new_point = tstart_galvo[-1] + slope * (trial_start[-1] - trial_start[-2])\n",
    "#     tstart_galvo = np.concatenate((tstart_galvo, new_point[np.newaxis]))\n",
    "\n",
    "assert len(trial_start) == len(tstart_galvo)\n",
    "\n",
    "#### these two timestamp variables are in a different reference frame ####\n",
    "\n",
    "# run objects have an aligner method to switch between reference frames\n",
    "galvo_ms = runs[0].aligner.B_to_A(tstart_galvo)\n",
    "\n",
    "print('microcontroller trial starts occur on average {} ms from galvo trial starts'\n",
    "      .format(round(np.mean(trial_start - galvo_ms), 2)))\n",
    "\n",
    "\n",
    "assert runs[0].frames_ms.shape == runs[0].flu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a different number of cells were stimulated on each trial\n",
    "### need to create a Subsets object to get this info (future code refinement will\n",
    "### include this info directly in the run object\n",
    "subsets = Subsets(runs[0])\n",
    "trial_subsets = subsets.trial_subsets\n",
    "# print(trial_subsets[5:20])\n",
    "n_stim_arr = np.unique(trial_subsets)\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.bar(np.arange(len(n_stim_arr)), height=[np.sum(trial_subsets == x) for x in n_stim_arr])\n",
    "plt.xticks(np.arange(len(n_stim_arr)), (str(x) for x in n_stim_arr))\n",
    "plt.xlabel(\"# PS\"); plt.ylabel('freq'); plt.title('distribution n_PS')\n",
    "### the result of the behavioural trial is in the run.oucome array\n",
    "\n",
    "plt.subplot(122)\n",
    "outcome = runs[0].outcome\n",
    "outcome_arr = np.unique(outcome)\n",
    "# print(outcome[5:20])\n",
    "plt.bar(np.arange(len(outcome_arr)), height=[np.sum(outcome == x) for x in outcome_arr])\n",
    "plt.xticks(np.arange(len(outcome_arr)), (str(x) for x in outcome_arr))\n",
    "plt.xlabel('behavior'); plt.ylabel('freq'); plt.title('behavior distr')\n",
    "assert len(runs[0].outcome) == len(tstart_galvo) == len(subsets.trial_subsets)\n",
    "\n",
    "\n",
    "# licks = runs[0].session.times.get('lick_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of frames before trial start to take into array\n",
    "pre_frames = 20\n",
    "# the number of frames after trial start to take into array\n",
    "post_frames = 30\n",
    "# array of fluoresence through behavioural trials (n_cells x n_trials x n_frames)\n",
    "# with e.g. the first trials spanning (galvo_ms[0] - pre_frames) : (galvo_ms[0] + post_frames)\n",
    "behaviour_trials = utils.build_flu_array(runs[0], galvo_ms, pre_frames, post_frames)\n",
    "\n",
    "print(f'Shape new array : {behaviour_trials.shape}')\n",
    "assert behaviour_trials.shape[1] == outcome.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_trials = behaviour_trials - np.nanmean(behaviour_trials, (1, 2))[:, np.newaxis, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = np.logical_or(outcome == 'hit', outcome == 'fp').astype('int')\n",
    "photostim = np.ones_like(trial_subsets)  # ones = 5-50\n",
    "photostim[trial_subsets == 0] = 0\n",
    "photostim[trial_subsets == 150] = 2\n",
    "assert photostim.shape == decision.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_stims = len(np.unique(photostim))\n",
    "n_neurons = behaviour_trials.shape[0]\n",
    "n_times = behaviour_trials.shape[2]\n",
    "n_trials = behaviour_trials.shape[1]\n",
    "n_unique_dec = len(np.unique(decision))\n",
    "occ_table = np.zeros((n_unique_stims, 2))  # stim x dec\n",
    "for dec in range(n_unique_dec):\n",
    "    for stim in range(n_unique_stims):\n",
    "        occ_table[stim, dec] = np.sum(np.logical_and(decision == dec, photostim == stim))\n",
    "n_com_trials = np.max(occ_table).astype('int')\n",
    "print(occ_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_gap_start = 19\n",
    "art_gap_stop = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = np.zeros((n_com_trials, n_neurons, n_unique_stims, n_unique_dec, n_times))\n",
    "activity = activity * np.nan\n",
    "nan_trials = np.isnan(np.mean(behaviour_trials, (0, 2)))\n",
    "min_common = 100\n",
    "max_common = 0\n",
    "for dec in range(n_unique_dec):\n",
    "    for stim in range(n_unique_stims):\n",
    "        inds_cond = np.logical_and(decision == dec, photostim == stim)\n",
    "        inds_cond = np.logical_and(inds_cond, np.logical_not(nan_trials))\n",
    "        current_data = np.squeeze(behaviour_trials[:, inds_cond, :])\n",
    "        n_curr_trials = current_data.shape[1]\n",
    "        activity[:n_curr_trials, :, stim, dec, :] = np.swapaxes(current_data, 0, 1)\n",
    "        max_common = np.maximum(max_common, current_data.shape[1])\n",
    "        min_common = np.minimum(min_common, current_data.shape[1])\n",
    "        print(current_data.shape)\n",
    "# n_com_trials = np.minimum(n_com_trials, min_common)\n",
    "n_com_trials = np.minimum(n_com_trials, max_common)\n",
    "\n",
    "activity = activity[:n_com_trials, :, :, :, :]\n",
    "n_unique_stims = 2\n",
    "activity = activity[:, :, :n_unique_stims, :, :]  # filter out PS = 150 trials\n",
    "filter_ps_array = np.concatenate((np.arange(art_gap_start), \n",
    "                                  np.arange(art_gap_stop, pre_frames + post_frames)))  # filter out few frames around PS\n",
    "old_act = activity.copy()\n",
    "activity = activity[:, :, :, :, filter_ps_array]\n",
    "activity_av = np.nanmean(activity, 0)\n",
    "\n",
    "plt.plot(np.nanmean(old_act, (0, 1, 2, 3)), label='activity all times')\n",
    "plt.plot(np.nanmean(activity, (0, 1, 2, 3)), label='activity filtered times')\n",
    "print(activity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpca = dPCA.dPCA(labels='sdt', n_components=5, regularizer='auto')\n",
    "dpca.protect = ['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity[:, inds_pos_r2, :, :, :].shape\n",
    "# activity_av[inds_pos_r2, :, :, :].shape\n",
    "# Z = dpca.fit_transform(activity_av[inds_pos_r2, :, :, :], activity[:, inds_pos_r2, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = dpca.fit_transform(activity_av, activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = {}\n",
    "recon['st'] = (dpca.reconstruct(activity_av, marginalization='st').copy() +\n",
    "               dpca.reconstruct(activity_av, marginalization='s').copy())\n",
    "recon['dt'] = (dpca.reconstruct(activity_av, marginalization='dt').copy() +\n",
    "               dpca.reconstruct(activity_av, marginalization='d').copy())\n",
    "recon['sdt'] = (dpca.reconstruct(activity_av, marginalization='sdt').copy() +\n",
    "               dpca.reconstruct(activity_av, marginalization='sd').copy())\n",
    "recon['t'] = dpca.reconstruct(activity_av, marginalization='t').copy()\n",
    "recon['full'] = np.zeros_like(recon['st'])\n",
    "for cond in ['t', 'st', 'dt', 'sdt']:\n",
    "    recon['full'] += recon[cond]\n",
    "    \n",
    "tmp = dpca.transform(activity_av, marginalization=None)  # call this function to recompute explained_variance_ratio_ (for something reason/buggy this is reset upon every marginalizaiton for all dimensions that are not the marginalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_color = {0: 'purple', 1: 'green'}\n",
    "stim_linestyle = {0: '-', 1: '-'}\n",
    "stim_alpha = {0: 0.5, 1: 1, 2: 1}\n",
    "title_cond = {'t': 'condition independent', 's': 'photo-stimulus dependent',\n",
    "              'd': 'lick decision dependent', 'sd': 'lick / PS interaction'}\n",
    "label_cond = {'stim': {0: 'no PS', 1: 'PS'}, 'dec': {0: 'no lick', 1: 'lick'}}\n",
    "expl_var=0\n",
    "\n",
    "def plot_condition(ax, cond):\n",
    "    \"\"\"Function to plot 1 condition on axis object ax\"\"\"\n",
    "    for dec in range(n_unique_dec):  # loop through all conditions\n",
    "        for stim in range(n_unique_stims):\n",
    "            plot_array = None\n",
    "            plot_array = Z[cond][0, stim, dec, :].copy()  # data to plot\n",
    "            expl_var = dpca.explained_variance_ratio_[cond][0].copy()  # extra \n",
    "            if cond != 't':\n",
    "                plot_array += Z[cond + 't'][0, stim, dec, :].copy()\n",
    "                expl_var += dpca.explained_variance_ratio_[cond + 't'][0].copy()\n",
    "            ax.plot(filter_ps_array[:art_gap_start],\n",
    "                    plot_array[:art_gap_start], label=f'{label_cond[\"stim\"][stim]}, {label_cond[\"dec\"][dec]}',\n",
    "                     linestyle=stim_linestyle[stim], c=dec_color[dec], alpha=stim_alpha[stim], linewidth=2)\n",
    "            ax.plot(filter_ps_array[art_gap_start:],\n",
    "                    plot_array[art_gap_start:], #label=f'{label_cond[\"stim\"][stim]}, {label_cond[\"dec\"][dec]}',\n",
    "                     linestyle=stim_linestyle[stim], c=dec_color[dec], alpha=stim_alpha[stim], linewidth=2)\n",
    "    if i_row == 1:\n",
    "        ax.set_xlabel('Time (frames)'); \n",
    "    if i_col == 0:\n",
    "        ax.set_ylabel('Activity ($\\Delta$F/F)'); \n",
    "    ax.set_title(title_cond[cond] + f' 1st dPC,   $R^2$: {np.round(expl_var, 3)}')\n",
    "    if i_row == 0 and i_col == 0:\n",
    "        ax.legend()\n",
    "        \n",
    "plt.rcParams['figure.figsize'] = (12, 13)\n",
    "plt.subplots_adjust(hspace=0.6, wspace=0.2)\n",
    "fig, axes = plt.subplots(3, 2, gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "for i_row in range(2):\n",
    "    for i_col in range(2):\n",
    "        plot_condition(axes[i_row][i_col], list(title_cond.keys())[2 * i_row + i_col])\n",
    "        \n",
    "plt.subplot(3, 2, 5)\n",
    "sns.heatmap(occ_table, annot=True, xticklabels=['no lick', 'lick'], \n",
    "            yticklabels=['no PS', '5-50 PS', '150 PS (excl.)'])\n",
    "plt.yticks(rotation=0)\n",
    "b, t = plt.ylim() # correct for default cut off\n",
    "b += 0.5 # see https://github.com/mwaskom/seaborn/issues/1773\n",
    "t -= 0.5 # \n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.title('Occurence table')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "r2_dpca =  1- (np.mean(np.power(activity_av - recon['full'], 2), (1, 2, 3)) /\n",
    "            np.mean(np.power(activity_av - np.mean(activity_av, 3)[:, :,:, np.newaxis], 2), (1, 2, 3)))\n",
    "plt.hist(r2_dpca, bins=np.linspace(-1, 1, 20), density=True);\n",
    "plt.xlabel('R2 value per neuron'); plt.ylabel('PDF')\n",
    "# print(np.argsort(r2_dpca)[-5:])\n",
    "# print(r2_dpca[33])\n",
    "# plt.xlim([0, 1])\n",
    "\n",
    "plt.savefig(f'dPCA_results/dPCA_{mouse}_{run_number}.pdf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use sklearn metric for automated variance weighing\n",
    "# total r2? -> sum of individual r2 values?\n",
    "# weights vs r2 => correct zero for inexplicable neurons?\n",
    "# cluster s/d/sd (filter zero ish neurons by r2)\n",
    "# cosine angles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds_pos_r2 = np.where(r2_dpca > 0)[0]\n",
    "# print(inds_pos_r2.size / r2_dpca.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_id = 715\n",
    "\n",
    "# print(f'R2 of neuron {neuron_id}: {np.round(r2_dpca[neuron_id], 3)}')\n",
    "\n",
    "# for dec in range(n_unique_dec):  # loop through all conditions\n",
    "#     for stim in range(n_unique_stims):\n",
    "#         plt.plot(activity_av[neuron_id, stim, dec, :],label=f'{label_cond[\"dec\"][dec]}',\n",
    "#                      c=dec_color[dec], alpha=stim_alpha[stim], linewidth=2)\n",
    "#         plt.plot(recon['full'][neuron_id, stim, dec, :], ':', label=f'{label_cond[\"dec\"][dec]}',\n",
    "#                      c=dec_color[dec], alpha=stim_alpha[stim], linewidth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((dpca.D['s'] + dpca.D['st'])[:, 0].shape)\n",
    "# inds_pos_r2 = np.where(r2_dpca > 0)[0]\n",
    "# sns.regplot(dpca.D['t'][inds_pos_r2, 0],   #(dpca.D['s'] + dpca.D['st'])[inds_pos_r2, 0],\n",
    "#             (dpca.D['d'] + dpca.D['dt'])[inds_pos_r2, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
